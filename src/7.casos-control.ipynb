{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metas en este cuaderno:\n",
    "* encontrar funciones que permita establecer las variables X = expuestos y no expuestos\n",
    "* establecer la variable D, donde D=1 denota controles y D=0 los casos.\n",
    "* incoporar las variables C, que son el conjunto de covariables.\n",
    "* tendremos un indicador binario S, donde S=1 significa que la unidad esta presente en la muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Para evitar los molestos avisos.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder # importo el modulo para crear el objeto OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "DATA_PATH = \"../data/union/End\"\n",
    "def load_data_prep(data_path=DATA_PATH):\n",
    "    csv_path = os.path.join(data_path, \"dataset_final.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "def load_data_demo(data_path=DATA_PATH):\n",
    "    csv_path = os.path.join(data_path, \"dataset_demog.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar DataFrame\n",
    "df = load_data_prep()\n",
    "df_dem = load_data_demo()\n",
    "df1 = df.merge(df_dem, on=\"cod\", how=\"left\") # unimos las tablas con indice en \"cod\" y df_dem es incluida a la tabla df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorias del encoder: [array(['F', 'M'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "# Especificar las variables predictoras y la variable objetivo\n",
    "predictors = ['ccbd_qa', 'age', 'ccbd_diameter']  # 'gender' se eliminará temporalmente para la codificación one-hot\n",
    "outcome = 'label'\n",
    " # obtenemos la mariz binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ccbd_qa       age  ccbd_diameter  gender_F  gender_M\n",
      "ccbd_qa        1.000000 -0.115373       0.159116  0.110405 -0.110405\n",
      "age           -0.115373  1.000000      -0.237001  0.114119 -0.114119\n",
      "ccbd_diameter  0.159116 -0.237001       1.000000 -0.120694  0.120694\n",
      "gender_F       0.110405  0.114119      -0.120694  1.000000 -1.000000\n",
      "gender_M      -0.110405 -0.114119       0.120694 -1.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Codificación One-Hot para la variable 'gender'\n",
    "df1 = pd.get_dummies(df1, columns=['gender'])\n",
    "x_simple = df1[predictors + [\"gender_F\",\"gender_M\"]]\n",
    "my_r = x_simple.corr(method=\"spearman\")\n",
    "print(my_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto es exactamente igual que get_dummies para variables que transformadas son binarias \n",
    "#encoder = OneHotEncoder(sparse=False) # armamos el encoder. sparse=False nos devuelve una matriz comun a la que estamos acostumbrados (en vez de esparsa)\n",
    "#gender =  pd.DataFrame(df1['gender'])\n",
    "#encoder.fit(np.array(gender).reshape(-1,1)) # fiteo reshapeando el vector y_train como veníamos haciendo pues no tiene formato de matriz\n",
    "#Gender = pd.DataFrame(encoder.transform(np.array(gender).reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(df1[predictors + ['gender_F', 'gender_M']], df[outcome], test_size=0.2, random_state=42)\n",
    "\n",
    "# Lista de penalizaciones a probar\n",
    "penalties = ['l1', 'l2', 'elasticnet', 'none']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scale = StandardScaler() # Creamos el estandarizador para usarlo posteriormente\n",
    "\n",
    "# Ajustamos el estandarizador\n",
    "std_scale.fit(X_test)\n",
    "std_scale.fit(X_train)\n",
    "\n",
    "# Aplicamos el estandarizador y obtenemos la matriz de features escaleados\n",
    "X_test_scaled = std_scale.transform(X_test)\n",
    "X_scaled = std_scale.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informe de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56         9\n",
      "           1       0.64      0.64      0.64        11\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.60      0.60      0.60        20\n",
      "weighted avg       0.60      0.60      0.60        20\n",
      "\n",
      "AUC-ROC: 0.6868686868686869\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "model.fit(X_scaled, y_train)\n",
    "\n",
    "# Predecir las etiquetas en el conjunto de prueba\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Informe de clasificación\n",
    "print(\"Informe de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# AUC-ROC\n",
    "y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "auc_roc = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC-ROC: {auc_roc}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informe de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.56      0.67         9\n",
      "           1       0.71      0.91      0.80        11\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.77      0.73      0.73        20\n",
      "weighted avg       0.77      0.75      0.74        20\n",
      "\n",
      "AUC-ROC: 0.7777777777777778\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir las etiquetas en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Informe de clasificación\n",
    "print(\"Informe de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# AUC-ROC\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "auc_roc = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC-ROC: {auc_roc}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 0.20\n",
    "seed = 42\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(df1[predictors + ['gender_F', 'gender_M']], df1[outcome], test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(l1_ratio=0.5, max_iter=10000, penalty=&#x27;elasticnet&#x27;,\n",
       "                   solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(l1_ratio=0.5, max_iter=10000, penalty=&#x27;elasticnet&#x27;,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(l1_ratio=0.5, max_iter=10000, penalty='elasticnet',\n",
       "                   solver='saga')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.530357 (0.168473)\n"
     ]
    }
   ],
   "source": [
    "name='Logistic Regression'\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "cv_results = model_selection.cross_val_score(model_, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  4]\n",
      " [ 1 10]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informe de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.56      0.67         9\n",
      "           1       0.71      0.91      0.80        11\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.77      0.73      0.73        20\n",
      "weighted avg       0.77      0.75      0.74        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Informe de clasificación\n",
    "print(\"Informe de Clasificación:\")\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informe de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56         9\n",
      "           1       0.64      0.64      0.64        11\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.60      0.60      0.60        20\n",
      "weighted avg       0.60      0.60      0.60        20\n",
      "\n",
      "AUC-ROC: 0.7070707070707071\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "regLog = LogisticRegression(penalty = 'none') # Inicializamos nuevamente el modelo\n",
    "regLog.fit(X_scaled, y_train) # Entrenar el modelo\n",
    "\n",
    "# Predecir las etiquetas en el conjunto de prueba\n",
    "y_pred = regLog.predict(X_test_scaled)\n",
    "\n",
    "# Informe de clasificación\n",
    "print(\"Informe de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# AUC-ROC\n",
    "y_prob = regLog.predict_proba(X_test_scaled)[:, 1]\n",
    "auc_roc = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC-ROC: {auc_roc}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "std_robust = RobustScaler() # Creamos el estandarizador para usarlo posteriormente\n",
    "\n",
    "# Ajustamos el estandarizador\n",
    "std_robust.fit(X_test)\n",
    "std_robust.fit(X_train)\n",
    "\n",
    "# Aplicamos el estandarizador y obtenemos la matriz de features escaleados\n",
    "X_test_stdrob = std_robust.transform(X_test)\n",
    "X_stdrob = std_robust.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informe de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56         9\n",
      "           1       0.64      0.64      0.64        11\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.60      0.60      0.60        20\n",
      "weighted avg       0.60      0.60      0.60        20\n",
      "\n",
      "AUC-ROC: 0.7070707070707071\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "regLog = LogisticRegression(penalty = 'none') # Inicializamos nuevamente el modelo\n",
    "regLog.fit(X_stdrob, y_train) # Entrenar el modelo\n",
    "\n",
    "# Predecir las etiquetas en el conjunto de prueba\n",
    "y_pred = regLog.predict(X_test_stdrob)\n",
    "\n",
    "# Informe de clasificación\n",
    "print(\"Informe de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# AUC-ROC\n",
    "y_prob = regLog.predict_proba(X_test_stdrob)[:, 1]\n",
    "auc_roc = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC-ROC: {auc_roc}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4821762 , -0.70588235, -0.32721347,  1.        , -1.        ],\n",
       "       [ 0.5308127 ,  0.58823529,  0.49570338,  0.        ,  0.        ],\n",
       "       [ 0.00513857, -0.58823529,  0.41433632,  1.        , -1.        ],\n",
       "       [ 0.34254494, -0.23529412, -0.63049069,  1.        , -1.        ],\n",
       "       [ 0.7578397 , -0.58823529, -1.39633501,  0.        ,  0.        ],\n",
       "       [-0.8735076 ,  0.47058824,  0.00729298,  1.        , -1.        ],\n",
       "       [-0.07860819, -0.47058824,  0.00678444,  0.        ,  0.        ],\n",
       "       [-1.15977816,  0.58823529, -0.54029345,  0.        ,  0.        ],\n",
       "       [-1.11211139, -0.58823529, -1.47918148,  0.        ,  0.        ],\n",
       "       [-0.76578749,  0.47058824, -0.8221887 ,  0.        ,  0.        ],\n",
       "       [ 0.6645156 ,  1.        , -0.26595702,  1.        , -1.        ],\n",
       "       [ 1.14319276,  0.64705882, -1.49906093,  0.        ,  0.        ],\n",
       "       [ 0.37092707, -0.41176471,  0.23343331,  1.        , -1.        ],\n",
       "       [-0.24816114, -0.11764706,  0.59426848,  1.        , -1.        ],\n",
       "       [ 0.50822897, -0.52941176,  1.09902163,  0.        ,  0.        ],\n",
       "       [ 0.50869884, -0.58823529, -0.27309975,  0.        ,  0.        ],\n",
       "       [-0.87096831, -0.17647059, -1.48392018,  1.        , -1.        ],\n",
       "       [-0.01662539, -0.23529412,  0.37062464,  0.        ,  0.        ],\n",
       "       [ 0.57883937, -0.47058824, -0.68686974,  1.        , -1.        ],\n",
       "       [ 0.66390577,  0.41176471,  0.68092902,  0.        ,  0.        ],\n",
       "       [ 0.60379245, -0.64705882,  0.13214057,  0.        ,  0.        ],\n",
       "       [-0.09682313, -0.23529412,  0.68818733,  0.        ,  0.        ],\n",
       "       [-0.44735586,  0.94117647,  0.374693  ,  0.        ,  0.        ],\n",
       "       [ 0.52184519, -0.64705882,  0.51211549,  0.        ,  0.        ],\n",
       "       [-1.11558043,  0.82352941,  0.56091261,  0.        ,  0.        ],\n",
       "       [-0.02238379,  0.52941176,  0.42892229,  1.        , -1.        ],\n",
       "       [ 0.25777847,  0.        ,  0.47094653,  0.        ,  0.        ],\n",
       "       [ 0.93535044,  0.88235294, -0.87343608,  0.        ,  0.        ],\n",
       "       [ 0.2832314 ,  0.58823529, -0.48003097,  1.        , -1.        ],\n",
       "       [ 0.05213553,  0.        ,  0.65173396,  1.        , -1.        ],\n",
       "       [-0.79399967,  0.05882353, -0.16034165,  0.        ,  0.        ],\n",
       "       [ 0.02338351, -0.64705882, -0.55619701,  1.        , -1.        ],\n",
       "       [-0.72332928,  0.29411765, -0.63904347,  0.        ,  0.        ],\n",
       "       [ 0.41776407, -0.58823529,  0.33017227,  0.        ,  0.        ],\n",
       "       [ 0.65495825,  0.41176471, -0.55393168,  1.        , -1.        ],\n",
       "       [-1.2742464 ,  0.88235294, -0.86458279,  0.        ,  0.        ],\n",
       "       [ 1.37178933, -0.70588235,  0.45992037,  1.        , -1.        ],\n",
       "       [ 0.18275928,  0.88235294,  0.0739585 ,  0.        ,  0.        ],\n",
       "       [-0.12475538, -0.17647059,  0.24878209,  0.        ,  0.        ],\n",
       "       [ 0.18977734, -0.47058824, -0.56479603,  0.        ,  0.        ],\n",
       "       [-0.58031896,  0.88235294,  0.31417625,  0.        ,  0.        ],\n",
       "       [-0.19901477, -0.52941176,  1.00484851,  0.        ,  0.        ],\n",
       "       [-1.21502283,  0.23529412, -0.63439723,  0.        ,  0.        ],\n",
       "       [-1.16626636, -0.29411765, -1.31478303,  0.        ,  0.        ],\n",
       "       [ 0.45497374, -0.41176471, -0.04004785,  0.        ,  0.        ],\n",
       "       [ 0.04173842,  0.58823529,  0.57540611,  0.        ,  0.        ],\n",
       "       [-0.49108372,  0.94117647, -1.82099247,  1.        , -1.        ],\n",
       "       [-0.00513857, -0.05882353,  0.38601966,  0.        ,  0.        ],\n",
       "       [ 0.89150261,  0.23529412, -0.08916859,  0.        ,  0.        ],\n",
       "       [-0.9491966 , -0.52941176,  0.97433586,  0.        ,  0.        ],\n",
       "       [-0.56379355, -0.58823529,  0.3411522 ,  0.        ,  0.        ],\n",
       "       [ 0.50573966, -0.05882353, -0.18798796,  1.        , -1.        ],\n",
       "       [ 0.29824724,  0.47058824,  0.41539964,  0.        ,  0.        ],\n",
       "       [ 0.04171842, -0.64705882, -0.13454459,  0.        ,  0.        ],\n",
       "       [-1.04984867,  0.23529412, -0.00703871,  0.        ,  0.        ],\n",
       "       [ 0.14201059,  0.52941176, -0.00678444,  0.        ,  0.        ],\n",
       "       [ 0.25815836, -0.47058824,  0.26426957,  0.        ,  0.        ],\n",
       "       [ 0.96347264, -0.17647059,  0.26641933,  1.        , -1.        ],\n",
       "       [-0.42322256,  0.94117647, -0.03852222,  1.        , -1.        ],\n",
       "       [-1.23442745, -0.11764706,  0.43467809,  0.        ,  0.        ],\n",
       "       [ 0.22416779,  0.17647059, -0.03269708,  1.        , -1.        ],\n",
       "       [-1.44704944,  0.94117647, -0.65575608,  0.        ,  0.        ],\n",
       "       [ 0.29575793,  0.64705882, -0.97022127,  1.        , -1.        ],\n",
       "       [-0.42983072, -0.05882353,  0.62330172,  0.        ,  0.        ],\n",
       "       [-1.13562486, -0.70588235, -0.47878273,  0.        ,  0.        ],\n",
       "       [-0.35453162, -0.47058824,  0.50802402,  1.        , -1.        ],\n",
       "       [ 1.59575718, -0.47058824,  0.27543443,  0.        ,  0.        ],\n",
       "       [-0.4681001 ,  0.23529412,  0.18907439,  1.        , -1.        ],\n",
       "       [-0.02165399,  0.        ,  0.641748  ,  0.        ,  0.        ],\n",
       "       [ 0.19953463,  0.35294118, -1.21866819,  0.        ,  0.        ],\n",
       "       [-0.62513652,  0.70588235, -0.70439139,  1.        , -1.        ],\n",
       "       [-0.06651154,  0.47058824, -0.8357807 ,  1.        , -1.        ],\n",
       "       [-0.15773623,  0.41176471,  0.64260328,  0.        ,  0.        ],\n",
       "       [-1.75467608,  0.94117647, -2.0729992 ,  0.        ,  0.        ],\n",
       "       [ 0.97071063, -0.23529412, -0.00928093,  0.        ,  0.        ],\n",
       "       [ 0.42444222,  0.41176471,  0.18311056,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_stdrob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ccbd_qa</th>\n",
       "      <th>age</th>\n",
       "      <th>ccbd_diameter</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.186186</td>\n",
       "      <td>21</td>\n",
       "      <td>26.7297</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.287513</td>\n",
       "      <td>43</td>\n",
       "      <td>30.2897</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.234931</td>\n",
       "      <td>23</td>\n",
       "      <td>29.9377</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.268681</td>\n",
       "      <td>29</td>\n",
       "      <td>25.4177</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.310222</td>\n",
       "      <td>23</td>\n",
       "      <td>22.1046</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.227764</td>\n",
       "      <td>41</td>\n",
       "      <td>24.5296</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.218639</td>\n",
       "      <td>40</td>\n",
       "      <td>30.9252</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.058901</td>\n",
       "      <td>49</td>\n",
       "      <td>19.1773</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.331515</td>\n",
       "      <td>29</td>\n",
       "      <td>28.1051</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.276873</td>\n",
       "      <td>40</td>\n",
       "      <td>28.9374</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ccbd_qa  age  ccbd_diameter  gender_F  gender_M\n",
       "40  0.186186   21        26.7297      True     False\n",
       "67  0.287513   43        30.2897     False      True\n",
       "15  0.234931   23        29.9377      True     False\n",
       "68  0.268681   29        25.4177      True     False\n",
       "88  0.310222   23        22.1046     False      True\n",
       "..       ...  ...            ...       ...       ...\n",
       "60  0.227764   41        24.5296      True     False\n",
       "71  0.218639   40        30.9252     False      True\n",
       "14  0.058901   49        19.1773     False      True\n",
       "92  0.331515   29        28.1051     False      True\n",
       "51  0.276873   40        28.9374     False      True\n",
       "\n",
       "[76 rows x 5 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regLog = LogisticRegression(penalty = 'none') # Inicializamos nuevamente el modelo\n",
    "regLog.fit(X, y) # Ajustamos el modelo con los parámetros\n",
    "score = regLog.score(X,y) # Calculamos el score\n",
    "beta_0 = regLog.intercept_ # El beta 0\n",
    "beta_1 = regLog.coef_[0][0] # El coeficiente beta_1\n",
    "beta_2 = regLog.coef_[0][1] # El coeficiente beta_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
