{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizador (transforma las variables en z-scores)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_accuracy(cm): # funcion para calcular la \"balanced accuracy\"\n",
    "  sensibilidad = cm[1,1]/(cm[1,1]+cm[0,1])\n",
    "  especificidad = cm[0,0]/(cm[1,0]+cm[0,0])\n",
    "  return [sensibilidad, especificidad, (sensibilidad + especificidad)/2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/union/End\"\n",
    "def load_data_prep(data_path=DATA_PATH):\n",
    "    csv_path = os.path.join(data_path, \"dataset_final.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión de la matriz de features: (67, 290)\n",
      "Dimensión del vector a predecir: (67,)\n",
      "Vector a predecir: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Variable a predecir\n",
    "target = 'label'\n",
    "\n",
    "# Construcción de la matriz de features\n",
    "X = df.drop(['cod', 'label'], axis=1)\n",
    "\n",
    "# Construcción del vector a predecir\n",
    "y = df[target].values\n",
    "\n",
    "print('Dimensión de la matriz de features: {}'.format(X.shape))\n",
    "print('Dimensión del vector a predecir: {}'.format(y.shape))\n",
    "print('Vector a predecir: {}'.format(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión de la matriz de features para entrenamiento: (60, 290)\n",
      "Dimensión de la matriz de features para testeo: (7, 290)\n"
     ]
    }
   ],
   "source": [
    "# Solo por esta vez para a fijar la semilla de numeros aleatorios\n",
    "# para que se separe siempre igual cada vez que corramos esta notebook \n",
    "random_seed = 123475\n",
    "\n",
    "# Creacion de las matrices de entrenamiento y testeo. Aca fijamos la semilla para que siempre separe igual\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state = random_seed)\n",
    "\n",
    "print('Dimensión de la matriz de features para entrenamiento: {}'.format(X_train.shape))\n",
    "print('Dimensión de la matriz de features para testeo: {}'.format(X_test.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "std_scale = StandardScaler() # Creamos el estandarizador para usarlo posteriormente\n",
    "\n",
    "# Ajustamos el estandarizador\n",
    "std_scale.fit(X_test)\n",
    "std_scale.fit(X_train)\n",
    "\n",
    "# Aplicamos el estandarizador y obtenemos la matriz de features escaleados\n",
    "X_test_scaled = std_scale.transform(X_test)\n",
    "X_scaled = std_scale.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "# random forest model creation\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_scaled,y_train)\n",
    "# predictions\n",
    "rfc_predict = rfc.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.6891666666666667\n"
     ]
    }
   ],
   "source": [
    "## Corremos el modelo con cross validation\n",
    "rfc_cv_score = cross_val_score(rfc, X, y, cv=10, scoring='roc_auc')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\hcgalvan\\Repositorios\\hcgalvan_project\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000, 'max_features': 'auto', 'max_depth': 420}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# number of features at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# max depth\n",
    "max_depth = [int(x) for x in np.linspace(100, 500, num = 11)]\n",
    "max_depth.append(None)\n",
    "# create random grid\n",
    "random_grid = {\n",
    " 'n_estimators': n_estimators,\n",
    " 'max_features': max_features,\n",
    " 'max_depth': max_depth\n",
    " }\n",
    "# Random search of parameters\n",
    "rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the model\n",
    "rfc_random.fit(X_scaled, y_train)\n",
    "# print results\n",
    "print(rfc_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Matriz de confusión ===\n",
      "[[0 3]\n",
      " [1 3]]\n",
      "\n",
      "\n",
      "=== Informe de clasificación ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.50      0.75      0.60         4\n",
      "\n",
      "    accuracy                           0.43         7\n",
      "   macro avg       0.25      0.38      0.30         7\n",
      "weighted avg       0.29      0.43      0.34         7\n",
      "\n",
      "\n",
      "\n",
      "=== Todas las puntuaciones de AUC ===\n",
      "[0.3        0.75       0.54166667 0.70833333 0.45833333 0.33333333\n",
      " 0.66666667 0.375      0.5        0.625     ]\n",
      "\\ n\n",
      "=== Puntuación AUC media ===\n",
      "Puntuación AUC media - Random Forest:  0.5258333333333333\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=20, max_depth=100, max_features='sqrt') \n",
    "rfc.fit(X_train,y_train) \n",
    "rfc_predict = rfc.predict(X_test) \n",
    "rfc_cv_score = cross_val_score(rfc, X, y, cv=10, scoring='roc_auc')\n",
    "print(\"=== Matriz de confusión ===\") \n",
    "print(confusion_matrix(y_test, rfc_predict)) \n",
    "print('\\n')\n",
    "print(\"=== Informe de clasificación ===\") \n",
    "print(classification_report(y_test, rfc_predict)) \n",
    "print('\\n')\n",
    "print(\"=== Todas las puntuaciones de AUC ===\")\n",
    "print(rfc_cv_score) \n",
    "print ('\\n')\n",
    "print(\"=== Puntuación AUC media ===\") \n",
    "print(\"Puntuación AUC media - Random Forest: \", rfc_cv_score.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
